{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/Assignments/INFO5731_Assignment_Four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "USSdXHuqnwv9"
   },
   "source": [
    "# **INFO5731 Assignment Four**\n",
    "\n",
    "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YWxodXh5n4xF"
   },
   "source": [
    "# **Question 1: Topic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TenBkDJ5n95k"
   },
   "source": [
    "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
    "\n",
    "(1) Features (text representation) used for topic modeling.\n",
    "\n",
    "(2) Top 10 clusters for topic modeling.\n",
    "\n",
    "(3) Summarize and describe the topic for each cluster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PuFPKhC0m1fd"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>strong suit first avatar movie sure story rete...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>sequel design look match first film longer imp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>james cameron film impressive special effect c...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>dumbest thing could possibly donesthey within ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>james cameron brings biggest disappointment ye...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>795</td>\n",
       "      <td>start visually marvel scenery character design...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>796</td>\n",
       "      <td>ive never seen beautiful cinematography vfx us...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>797</td>\n",
       "      <td>absolutley flabbergasted cgi effect movie wate...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>798</td>\n",
       "      <td>opened early thailand wednesday morning tuesda...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>799</td>\n",
       "      <td>true review film available released home video...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>799 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     document_id                                    Cleaned Reviews sentiment\n",
       "0              1  strong suit first avatar movie sure story rete...  Positive\n",
       "1              2  sequel design look match first film longer imp...  Positive\n",
       "2              3  james cameron film impressive special effect c...  Positive\n",
       "3              4  dumbest thing could possibly donesthey within ...  Positive\n",
       "4              5  james cameron brings biggest disappointment ye...  Negative\n",
       "..           ...                                                ...       ...\n",
       "794          795  start visually marvel scenery character design...  Positive\n",
       "795          796  ive never seen beautiful cinematography vfx us...  Positive\n",
       "796          797  absolutley flabbergasted cgi effect movie wate...  Positive\n",
       "797          798  opened early thailand wednesday morning tuesda...  Positive\n",
       "798          799  true review film available released home video...  Positive\n",
       "\n",
       "[799 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/jeevankumar20/INFO_5731_Spring2023/main/annotated_reviews.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "(0, '0.014*\"movie\" + 0.013*\"avatar\" + 0.011*\"story\" + 0.010*\"film\" + 0.007*\"cameron\" + 0.007*\"way\" + 0.007*\"one\" + 0.006*\"water\" + 0.006*\"new\" + 0.006*\"character\"')\n",
      "Topic 1:\n",
      "(1, '0.021*\"movie\" + 0.011*\"film\" + 0.010*\"story\" + 0.008*\"time\" + 0.007*\"people\" + 0.007*\"character\" + 0.007*\"way\" + 0.007*\"avatar\" + 0.006*\"one\" + 0.006*\"first\"')\n",
      "Topic 2:\n",
      "(2, '0.026*\"movie\" + 0.016*\"film\" + 0.015*\"first\" + 0.013*\"avatar\" + 0.012*\"one\" + 0.012*\"like\" + 0.010*\"story\" + 0.009*\"cameron\" + 0.009*\"character\" + 0.008*\"way\"')\n",
      "Topic 3:\n",
      "(3, '0.032*\"movie\" + 0.013*\"story\" + 0.010*\"film\" + 0.009*\"first\" + 0.009*\"like\" + 0.008*\"character\" + 0.007*\"avatar\" + 0.006*\"visuals\" + 0.006*\"one\" + 0.006*\"plot\"')\n",
      "Topic 4:\n",
      "(4, '0.001*\"couldve\" + 0.001*\"issue\" + 0.001*\"many\" + 0.001*\"pro\" + 0.001*\"hourweirdly\" + 0.001*\"prettyaddresses\" + 0.001*\"charactersdidnt\" + 0.001*\"conflictoverall\" + 0.001*\"focussed\" + 0.001*\"numb\"')\n",
      "Topic 5:\n",
      "(5, '0.015*\"film\" + 0.008*\"movie\" + 0.007*\"story\" + 0.007*\"avatar\" + 0.006*\"like\" + 0.006*\"first\" + 0.006*\"way\" + 0.005*\"also\" + 0.005*\"cameron\" + 0.005*\"character\"')\n",
      "Topic 6:\n",
      "(6, '0.016*\"movie\" + 0.011*\"film\" + 0.010*\"story\" + 0.009*\"character\" + 0.008*\"one\" + 0.008*\"first\" + 0.007*\"avatar\" + 0.007*\"water\" + 0.006*\"like\" + 0.006*\"way\"')\n",
      "Topic 7:\n",
      "(7, '0.019*\"movie\" + 0.008*\"avatar\" + 0.006*\"like\" + 0.006*\"one\" + 0.006*\"story\" + 0.005*\"character\" + 0.005*\"time\" + 0.005*\"people\" + 0.005*\"long\" + 0.004*\"u\"')\n",
      "Topic 8:\n",
      "(8, '0.015*\"movie\" + 0.013*\"film\" + 0.011*\"avatar\" + 0.009*\"character\" + 0.008*\"one\" + 0.007*\"first\" + 0.007*\"way\" + 0.006*\"people\" + 0.006*\"like\" + 0.006*\"year\"')\n",
      "Topic 9:\n",
      "(9, '0.018*\"movie\" + 0.011*\"really\" + 0.011*\"one\" + 0.010*\"film\" + 0.010*\"story\" + 0.009*\"character\" + 0.008*\"like\" + 0.008*\"first\" + 0.006*\"avatar\" + 0.006*\"get\"')\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "\n",
    "# Tokenize the text\n",
    "corpus = df['Cleaned Reviews'].apply(str.split)\n",
    "\n",
    "# Create a dictionary with the corpus\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "\n",
    "# Convert corpus into a bag of words\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in corpus]\n",
    "\n",
    "# Build the LDA model\n",
    "num_topics = 10\n",
    "lda_model = LdaModel(corpus=bow_corpus, id2word=dictionary, num_topics=num_topics, passes=10, alpha='auto')\n",
    "\n",
    "# Print the top 10 clusters/topics\n",
    "for index, topic in enumerate(lda_model.show_topics(num_topics=num_topics)):\n",
    "    print(f\"Topic {index}:\")\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Topic 0 score</th>\n",
       "      <th>Topic 1 score</th>\n",
       "      <th>Topic 2 score</th>\n",
       "      <th>Topic 3 score</th>\n",
       "      <th>Topic 4 score</th>\n",
       "      <th>Topic 5 score</th>\n",
       "      <th>Topic 6 score</th>\n",
       "      <th>Topic 7 score</th>\n",
       "      <th>Topic 8 score</th>\n",
       "      <th>Topic 9 score</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strong suit first avatar movie sure story rete...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sequel design look match first film longer imp...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>james cameron film impressive special effect c...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dumbest thing could possibly donesthey within ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>james cameron brings biggest disappointment ye...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hard believe sequel avatar actually come year ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>technically gorgeous story similarly emotional...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>massive advertising make sure like many people...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>loved first movie likely love movie thin story...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>without question best cg work seen recent movi...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Topic 0 score  \\\n",
       "0  strong suit first avatar movie sure story rete...           1.00   \n",
       "1  sequel design look match first film longer imp...           0.19   \n",
       "2  james cameron film impressive special effect c...           0.99   \n",
       "3  dumbest thing could possibly donesthey within ...           1.00   \n",
       "4  james cameron brings biggest disappointment ye...           1.00   \n",
       "5  hard believe sequel avatar actually come year ...           1.00   \n",
       "6  technically gorgeous story similarly emotional...           0.99   \n",
       "7  massive advertising make sure like many people...           1.00   \n",
       "8  loved first movie likely love movie thin story...           0.41   \n",
       "9  without question best cg work seen recent movi...           1.00   \n",
       "\n",
       "   Topic 1 score  Topic 2 score  Topic 3 score  Topic 4 score  Topic 5 score  \\\n",
       "0           0.00           0.00            0.0              0              0   \n",
       "1           0.72           0.08            0.0              0              0   \n",
       "2           0.00           0.00            0.0              0              0   \n",
       "3           0.00           0.00            0.0              0              0   \n",
       "4           0.00           0.00            0.0              0              0   \n",
       "5           0.00           0.00            0.0              0              0   \n",
       "6           0.00           0.00            0.0              0              0   \n",
       "7           0.00           0.00            0.0              0              0   \n",
       "8           0.59           0.00            0.0              0              0   \n",
       "9           0.00           0.00            0.0              0              0   \n",
       "\n",
       "   Topic 6 score  Topic 7 score  Topic 8 score  Topic 9 score  Topic  \n",
       "0              0              0              0              0      0  \n",
       "1              0              0              0              0      1  \n",
       "2              0              0              0              0      0  \n",
       "3              0              0              0              0      0  \n",
       "4              0              0              0              0      0  \n",
       "5              0              0              0              0      0  \n",
       "6              0              0              0              0      0  \n",
       "7              0              0              0              0      0  \n",
       "8              0              0              0              0      1  \n",
       "9              0              0              0              0      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_lda = lda_model[bow_corpus]\n",
    "num_topics = 10\n",
    "scores = [[] for i in range(num_topics)]\n",
    "for doc in corpus_lda:\n",
    "    for i in range(num_topics):\n",
    "        if len(doc) > i:\n",
    "            scores[i].append(round(doc[i][1], 2))\n",
    "        else:\n",
    "            scores[i].append(0)\n",
    "\n",
    "# Create data frame that shows scores assigned for each topic for each review\n",
    "df_topic = pd.DataFrame()\n",
    "df_topic['Text'] = df['Cleaned Reviews']\n",
    "for i in range(num_topics):\n",
    "    df_topic[f'Topic {i} score'] = scores[i]\n",
    "df_topic['Topic'] = df_topic[[f'Topic {i} score' for i in range(num_topics)]].apply(lambda x: x.argmax(), axis=1)\n",
    "df_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfpMRCrRwN6Z"
   },
   "source": [
    "# **Question 2: Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dCQEbDawWCw"
   },
   "source": [
    "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
    "\n",
    "(1) Features used for sentiment classification and explain why you select these features.\n",
    "\n",
    "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
    "\n",
    "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vATjQNTY8buA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00        19\n",
      "    Positive       0.88      1.00      0.94       141\n",
      "\n",
      "    accuracy                           0.88       160\n",
      "   macro avg       0.44      0.50      0.47       160\n",
      "weighted avg       0.78      0.88      0.83       160\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.05      0.10        19\n",
      "    Positive       0.89      1.00      0.94       141\n",
      "\n",
      "    accuracy                           0.89       160\n",
      "   macro avg       0.94      0.53      0.52       160\n",
      "weighted avg       0.90      0.89      0.84       160\n",
      "\n",
      "Naive Bayes Cross-Validation Scores: [0.890625   0.890625   0.8828125  0.8828125  0.88976378]\n",
      "Random Forest Cross-Validation Scores: [0.890625   0.890625   0.8828125  0.8828125  0.88976378]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# load data\n",
    "\n",
    "X = df['Cleaned Reviews']\n",
    "y = df['sentiment']\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# preprocess text data using TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "\n",
    "# select features for classification\n",
    "features_train = X_train\n",
    "features_test = X_test\n",
    "\n",
    "# train and evaluate Naive Bayes classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(features_train, y_train)\n",
    "nb_preds = nb.predict(features_test)\n",
    "nb_report = classification_report(y_test, nb_preds)\n",
    "\n",
    "# train and evaluate Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(features_train, y_train)\n",
    "rf_preds = rf.predict(features_test)\n",
    "rf_report = classification_report(y_test, rf_preds)\n",
    "\n",
    "# cross-validation scores for Naive Bayes and Random Forest\n",
    "nb_scores = cross_val_score(nb, features_train, y_train, cv=5)\n",
    "rf_scores = cross_val_score(rf, features_train, y_train, cv=5)\n",
    "\n",
    "# print performance metrics\n",
    "print('Naive Bayes Classification Report:\\n', nb_report)\n",
    "print('Random Forest Classification Report:\\n', rf_report)\n",
    "print('Naive Bayes Cross-Validation Scores:', nb_scores)\n",
    "print('Random Forest Cross-Validation Scores:', rf_scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5mmYIfN8eYV"
   },
   "source": [
    "# **Question 3: House price prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hsi2y4z88ngX"
   },
   "source": [
    "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XfvMKJjIXS5G",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Write your code here\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train\n",
    "\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1444.000000</td>\n",
       "      <td>1458.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1458.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2190.000000</td>\n",
       "      <td>57.378341</td>\n",
       "      <td>68.580357</td>\n",
       "      <td>9819.161069</td>\n",
       "      <td>6.078821</td>\n",
       "      <td>5.553804</td>\n",
       "      <td>1971.357779</td>\n",
       "      <td>1983.662783</td>\n",
       "      <td>100.709141</td>\n",
       "      <td>439.203704</td>\n",
       "      <td>...</td>\n",
       "      <td>472.768861</td>\n",
       "      <td>93.174777</td>\n",
       "      <td>48.313914</td>\n",
       "      <td>24.243317</td>\n",
       "      <td>1.794380</td>\n",
       "      <td>17.064428</td>\n",
       "      <td>1.744345</td>\n",
       "      <td>58.167923</td>\n",
       "      <td>6.104181</td>\n",
       "      <td>2007.769705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.321334</td>\n",
       "      <td>42.746880</td>\n",
       "      <td>22.376841</td>\n",
       "      <td>4955.517327</td>\n",
       "      <td>1.436812</td>\n",
       "      <td>1.113740</td>\n",
       "      <td>30.390071</td>\n",
       "      <td>21.130467</td>\n",
       "      <td>177.625900</td>\n",
       "      <td>455.268042</td>\n",
       "      <td>...</td>\n",
       "      <td>217.048611</td>\n",
       "      <td>127.744882</td>\n",
       "      <td>68.883364</td>\n",
       "      <td>67.227765</td>\n",
       "      <td>20.207842</td>\n",
       "      <td>56.609763</td>\n",
       "      <td>30.491646</td>\n",
       "      <td>630.806978</td>\n",
       "      <td>2.722432</td>\n",
       "      <td>1.301740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1461.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1879.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1825.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>7391.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1953.000000</td>\n",
       "      <td>1963.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2190.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>9399.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>350.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2554.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11517.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>753.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2919.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>56600.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1488.000000</td>\n",
       "      <td>1424.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage       LotArea  OverallQual  \\\n",
       "count  1459.000000  1459.000000  1232.000000   1459.000000  1459.000000   \n",
       "mean   2190.000000    57.378341    68.580357   9819.161069     6.078821   \n",
       "std     421.321334    42.746880    22.376841   4955.517327     1.436812   \n",
       "min    1461.000000    20.000000    21.000000   1470.000000     1.000000   \n",
       "25%    1825.500000    20.000000    58.000000   7391.000000     5.000000   \n",
       "50%    2190.000000    50.000000    67.000000   9399.000000     6.000000   \n",
       "75%    2554.500000    70.000000    80.000000  11517.500000     7.000000   \n",
       "max    2919.000000   190.000000   200.000000  56600.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1459.000000  1459.000000   1459.000000  1444.000000  1458.000000  ...   \n",
       "mean      5.553804  1971.357779   1983.662783   100.709141   439.203704  ...   \n",
       "std       1.113740    30.390071     21.130467   177.625900   455.268042  ...   \n",
       "min       1.000000  1879.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1953.000000   1963.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1992.000000     0.000000   350.500000  ...   \n",
       "75%       6.000000  2001.000000   2004.000000   164.000000   753.500000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1290.000000  4010.000000  ...   \n",
       "\n",
       "        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count  1458.000000  1459.000000  1459.000000    1459.000000  1459.000000   \n",
       "mean    472.768861    93.174777    48.313914      24.243317     1.794380   \n",
       "std     217.048611   127.744882    68.883364      67.227765    20.207842   \n",
       "min       0.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "25%     318.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "50%     480.000000     0.000000    28.000000       0.000000     0.000000   \n",
       "75%     576.000000   168.000000    72.000000       0.000000     0.000000   \n",
       "max    1488.000000  1424.000000   742.000000    1012.000000   360.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \n",
       "count  1459.000000  1459.000000   1459.000000  1459.000000  1459.000000  \n",
       "mean     17.064428     1.744345     58.167923     6.104181  2007.769705  \n",
       "std      56.609763    30.491646    630.806978     2.722432     1.301740  \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000  \n",
       "25%       0.000000     0.000000      0.000000     4.000000  2007.000000  \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000  \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000  \n",
       "max     576.000000   800.000000  17000.000000    12.000000  2010.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n",
    "\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted House Prices:  [111157.42073515 303244.12309656  49450.53428339 135092.8286368\n",
      " 295598.52485442  17364.14968932 202498.14601255 105665.7563246\n",
      "  12638.17072703 104229.02033447 102361.11171031  65057.90023656\n",
      "  51348.49013592 180370.81421614 123041.40954705  91906.17087723\n",
      " 141820.58252766  78063.2693486   78906.02489875 167633.20238095\n",
      " 109636.40684354 161358.91445376 131224.51076025  88985.19078536\n",
      " 161765.61992442  99185.31012568 155005.60148728  43791.23306542\n",
      " 119193.54566119 163792.76630412  73496.14657419 220512.79618769\n",
      " 173972.58862631  62541.23602905 200888.40957453 101896.8502265\n",
      "  82608.56578322 163038.64647482 282383.8395715   86788.8694744\n",
      "  93178.51551367 175444.15286966  58676.86753581 297780.99965437\n",
      "  89208.69246158 109603.68625155  59738.26368787  96778.7145425\n",
      " 355996.96940297  84183.1038723   79042.01283484 188877.87415223\n",
      "  52424.66314941 224867.45974837 112983.87555741 185961.1289106\n",
      " 168186.20812844 139968.01707532  89097.10581305  59065.33867672\n",
      "  17565.47081928 133160.43080866 275212.71276827 220375.66803947\n",
      " 267702.16040511 162222.81992039  53960.02164408 242541.9194318\n",
      "  71476.32387559 123893.60613714  72696.19807565  79318.03644604\n",
      "  62247.50535845  14036.29581152 384286.92075136 152362.01395368\n",
      " 257391.53160364 307043.25935347 107905.06397406  66868.42484203\n",
      "  72087.63989665  24166.61813106  75572.39136159  56138.66389635\n",
      " 120721.0994372   98058.63327337 204091.03356868 171850.77794235\n",
      "  82322.55341461 151531.72511246  73389.20631549  89028.36387585\n",
      " 118185.30993411 229927.758585    71513.09303045 136715.23764978\n",
      " 174568.5770264  137205.34356207 159708.64172952 227609.4883444\n",
      "  83516.11949209 161340.79467674 217000.62183457  97525.59044091\n",
      " 141315.38538778 151786.53627605 105653.20783516 238952.46522216\n",
      " 110257.38737934 175663.16062107  15818.45278917 100953.10279477\n",
      " 108049.54600273  91791.27700891 160584.7186542   84181.18289333\n",
      "  60369.5577056   81087.68241189  80446.2691233  215603.90555919\n",
      "  72844.84544513  85270.82214615 140584.33175431 135912.36505187\n",
      " 142514.5697907   83475.01595913 181017.65616052  41643.66431922\n",
      " 106897.11329657 149545.02100446 142081.7093996  269467.11649591\n",
      " 155552.96481918 106503.93736396  17325.31539081 324036.42258361\n",
      " 297629.57938848 100388.01306531 179635.41429472 494467.64894591\n",
      " 300775.99440435  90817.24160798 140243.68048895  99736.97189048\n",
      "  57036.42865488  62633.89421718 207721.06568439 152274.95400202\n",
      "  77000.86381939  -4366.94415782  87951.22537174  67769.65386045\n",
      " 216016.33900111 115952.12375178  24028.00668828  64613.66662488\n",
      "  70756.79880646 114240.2727017   47962.76371608  97105.4134306\n",
      " 183400.04518956  64780.33756909 240867.4094163  107413.93265052\n",
      "  61081.07030422  93577.21145683 208831.56007518 281438.14866415\n",
      " 368443.00673054 180140.59684139 330539.42500939  46409.65976584\n",
      "  68390.6454186   99145.71053918 270619.87755054  70026.3457137\n",
      "  75161.92671376 162175.96017227  89556.92287935 116801.12481905\n",
      " 157253.36548952  87154.54883202  80896.46040057 111038.09113258\n",
      " 187179.30133651  40699.79800803 189969.02722135 161860.83019297\n",
      " 156578.87082147  27603.02695182  68420.58404503  63946.43208864\n",
      " 103363.87166708 124747.13650756 157415.8360564  157325.09334275\n",
      " 145413.46094768  64731.97639801 165064.70098047  86825.62029879\n",
      " 212196.05430215 178511.68496142  55522.57304738 268389.95052241\n",
      " 152935.68827066  71981.50251472 177854.0383592   92775.78162707\n",
      "  73998.87242976  59143.86279514 171104.38122772 113116.57649209\n",
      "  76514.48079632 123261.76482972 168138.24012578 202077.88121018\n",
      " 163325.24695119  78324.44249397  78029.02654993  74522.30517369\n",
      "  83289.77398584 174023.4952225  146087.69466462  51741.28785649\n",
      " 192196.27281118  96997.63306328  38814.05488692  52129.7555044\n",
      " 113464.26207504  74046.98806822  66618.06316218 117029.77504829\n",
      "  73604.08874419  70007.04545724 190331.6348964  102329.28026891\n",
      " 154705.91512197 120810.77003182 203278.56327099  66573.98482611\n",
      "  70366.02535471 202824.40632213 181366.0187012  424557.73678245\n",
      " 156149.22631716  83855.25195129  87091.67640657 121879.84884161\n",
      " 100330.28097152  57378.89256671 118313.63881344 118842.11346871\n",
      " 112130.10598624  80423.16752005  95645.21899291  82121.90819638\n",
      "  52817.12415199  79281.44807851 132609.57010204 186920.1993724\n",
      " 243159.03913139 142784.004742   104271.31632533 193801.37543562\n",
      " 295839.80513068 184774.987951   109060.53930135  84201.16882912\n",
      "  62917.42048474 145914.66815922 353441.72921668 195081.03864762\n",
      " 184616.13792937  29594.15743481  34298.86286272  87910.64765318\n",
      "  87084.85117725 261452.901833   204959.89242237  70066.52892572\n",
      " 152787.52533343  66348.17995453 158970.51128704  69585.69597063\n",
      " 252197.04899498 132681.38441872 158123.42833186  52574.16406137\n",
      " 242233.05005824 150475.8322367   44225.9890546   76646.27057566]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# extract features and target variable\n",
    "X = train.drop(\"SalePrice\", axis=1)\n",
    "y = train[\"SalePrice\"]\n",
    "\n",
    "\n",
    "# identify categorical features\n",
    "cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# define column transformer to apply one-hot encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "# split data into 80-20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# fill missing numerical values with mean\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_test.fillna(X_test.mean(), inplace=True)\n",
    "\n",
    "# fill missing categorical values with mode\n",
    "X_train.fillna(X_train.mode().iloc[0], inplace=True)\n",
    "X_test.fillna(X_test.mode().iloc[0], inplace=True)\n",
    "\n",
    "# fit a linear regression model on the train set\n",
    "lm = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())])\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = lm.predict(X_test)\n",
    "print(\"Predicted House Prices: \",y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5891788940391561"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# compute the R-squared value\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "INFO5731_Assignment_Three.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
